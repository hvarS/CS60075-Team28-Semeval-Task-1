{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from eval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/preprocessed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1 - Single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load train df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3ZLW647WALVGE8EBR50EGUBPU4P32A</th>\n",
       "      <td>bible</td>\n",
       "      <td>bible behold came river seven cattle sleek fat...</td>\n",
       "      <td>river</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34R0BODSP1ZBN3DVY8J8XSIY551E5C</th>\n",
       "      <td>bible</td>\n",
       "      <td>bible fellow bondservant brother prophet keep ...</td>\n",
       "      <td>brother</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</th>\n",
       "      <td>bible</td>\n",
       "      <td>bible man lord land said u know honest men lea...</td>\n",
       "      <td>brother</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3BFNCI9LYKQN09BHXHH9CLSX5KP738</th>\n",
       "      <td>bible</td>\n",
       "      <td>bible shimei sixteen son six daughter brother ...</td>\n",
       "      <td>brother</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</th>\n",
       "      <td>bible</td>\n",
       "      <td>bible put brother far</td>\n",
       "      <td>brother</td>\n",
       "      <td>0.263889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               corpus  \\\n",
       "id                                      \n",
       "3ZLW647WALVGE8EBR50EGUBPU4P32A  bible   \n",
       "34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible   \n",
       "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible   \n",
       "3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible   \n",
       "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible   \n",
       "\n",
       "                                                                         sentence  \\\n",
       "id                                                                                  \n",
       "3ZLW647WALVGE8EBR50EGUBPU4P32A  bible behold came river seven cattle sleek fat...   \n",
       "34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible fellow bondservant brother prophet keep ...   \n",
       "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible man lord land said u know honest men lea...   \n",
       "3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible shimei sixteen son six daughter brother ...   \n",
       "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2                              bible put brother far   \n",
       "\n",
       "                                  token  complexity  \n",
       "id                                                   \n",
       "3ZLW647WALVGE8EBR50EGUBPU4P32A    river    0.000000  \n",
       "34R0BODSP1ZBN3DVY8J8XSIY551E5C  brother    0.000000  \n",
       "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  brother    0.050000  \n",
       "3BFNCI9LYKQN09BHXHH9CLSX5KP738  brother    0.150000  \n",
       "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  brother    0.263889  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, \"lcp_single_train_preprocessed.csv\"), index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique tokens : 2856\n",
      "130 tokens not in vocab\n"
     ]
    }
   ],
   "source": [
    "# take mean of duplicate tokens\n",
    "# token not in vocab are considered as 'unk'\n",
    "\n",
    "df = df.groupby('token').mean().reset_index()\n",
    "print(\"unique tokens : {}\".format(len(df)))\n",
    "\n",
    "count = [True if w in word_vector else False for w in df['token']]\n",
    "print(\"{} tokens not in vocab\".format(len(df)-sum(count)))\n",
    "\n",
    "vectors = np.array(list(df['token'].apply(lambda x:word_vector[x] if x in word_vector else word_vector['unk'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 tokens not in vocab\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_folder, \"lcp_single_test_preprocessed.csv\"), index_col=0)\n",
    "count = [True if w in word_vector else False for w in test_df['token']]\n",
    "print(\"{} tokens not in vocab\".format(len(test_df)-sum(count)))\n",
    "\n",
    "testdf_vectors = np.array(list(test_df['token'].apply(lambda x:word_vector[x] if x in word_vector else word_vector['unk'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_folder = \"predictions/single\"\n",
    "\n",
    "# Linear Regression\n",
    "reg = LinearRegression().fit(vectors, np.array(df['complexity']))\n",
    "y_pred = reg.predict(testdf_vectors)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/linear_regression_baseline.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "reg = GradientBoostingRegressor().fit(vectors, np.array(df['complexity']))\n",
    "y_pred = reg.predict(testdf_vectors)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/gradient_boosting_baseline.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM regressor\n",
    "reg = SVR().fit(vectors, np.array(df['complexity']))\n",
    "y_pred = reg.predict(testdf_vectors)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/SVM_baseline.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Regressor\n",
    "regr = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(df['complexity']))\n",
    "y_pred = reg.predict(testdf_vectors)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/MLP_baseline.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file gradient_boosting_baseline.csv\n",
      "pearson  :  0.6469066684805035\n",
      "spearman :  0.62493976278848\n",
      "mae      :  0.0747125087856786\n",
      "mse      :  0.009504483612266126\n",
      "r2       :  0.4127624765030997\n",
      "\n",
      "For file SVM_baseline.csv\n",
      "pearson  :  0.6553534622949289\n",
      "spearman :  0.609787415042385\n",
      "mae      :  0.07787217407123892\n",
      "mse      :  0.009971588727391003\n",
      "r2       :  0.3839022393551641\n",
      "\n",
      "For file linear_regression_baseline.csv\n",
      "pearson  :  0.6639716433790339\n",
      "spearman :  0.6391991602453316\n",
      "mae      :  0.07316730116994907\n",
      "mse      :  0.009196928531600866\n",
      "r2       :  0.4317648643525217\n",
      "\n",
      "For file MLP_baseline.csv\n",
      "pearson  :  0.6553534622949289\n",
      "spearman :  0.609787415042385\n",
      "mae      :  0.07787217407123892\n",
      "mse      :  0.009971588727391003\n",
      "r2       :  0.3839022393551641\n"
     ]
    }
   ],
   "source": [
    "evaluate(submission_folder, \"references/lcp_single_test_labelled_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpTask1",
   "language": "python",
   "name": "nlptask1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
