{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselines.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XDM8FtGrv3Cu",
        "fH-qxn1zojp2",
        "Svgv6n9e-Q7I",
        "_1wXzYgmV2Mx",
        "7TIJwE4UsGOg",
        "vYQs4natxevq"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hvarS/CS60075-Team28-Task-1/blob/main/baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw13Jr9RdCrS"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZpllGi738qY",
        "outputId": "5dc3c919-7127-4abf-9ec1-ccdd94759b43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkQkKVA35L-3",
        "outputId": "f695237d-bb95-4a8b-8a75-37b3f4989c11"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d embeddings"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-10 06:02:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-04-10 06:02:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-04-10 06:02:25--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1        4%[                    ]  34.07M  11.5MB/s               ^C\n",
            "Archive:  glove.6B.zip\n",
            "replace embeddings/glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0IfcPd_6GR4"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr3O0KwxUfLR"
      },
      "source": [
        "FOLDER_PATH = \"/content/drive/MyDrive/CS60075-Team28-Task-1\"\n",
        "DATA_FOLDER = os.path.join(FOLDER_PATH,\"data/preprocessed\")"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbKLlGrPKfTu"
      },
      "source": [
        "# import evaluate function\n",
        "import sys\n",
        "sys.path.append(FOLDER_PATH)\n",
        "from eval import evaluate"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "LeyCMxKPtcOv",
        "outputId": "01126224-7951-4dfb-d448-8b0455aac216"
      },
      "source": [
        "data = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_single_train_preprocessed.csv\"), index_col=0)\n",
        "data['token'] = data['token'].astype(str)\n",
        "data['sentence'] = data['sentence'].astype(str)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3ZLW647WALVGE8EBR50EGUBPU4P32A</th>\n",
              "      <td>bible</td>\n",
              "      <td>behold came river seven cattle sleek fat fed m...</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34R0BODSP1ZBN3DVY8J8XSIY551E5C</th>\n",
              "      <td>bible</td>\n",
              "      <td>fellow bondservant brother prophet keep word book</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</th>\n",
              "      <td>bible</td>\n",
              "      <td>man lord land said u know honest men leave one...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3BFNCI9LYKQN09BHXHH9CLSX5KP738</th>\n",
              "      <td>bible</td>\n",
              "      <td>shimei sixteen son six daughter brother didnt ...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</th>\n",
              "      <td>bible</td>\n",
              "      <td>put brother far</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.263889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               corpus  ... complexity\n",
              "id                                     ...           \n",
              "3ZLW647WALVGE8EBR50EGUBPU4P32A  bible  ...   0.000000\n",
              "34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible  ...   0.000000\n",
              "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible  ...   0.050000\n",
              "3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible  ...   0.150000\n",
              "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible  ...   0.263889\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "yQ_QxnnMp6eV",
        "outputId": "8bae93fa-9773-4bcf-8940-de96a59c9300"
      },
      "source": [
        "data_multi = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_multi_train_preprocessed.csv\"), index_col=0)\n",
        "data_multi['token'] = data_multi['token'].astype(str)\n",
        "data_multi['sentence'] = data_multi['sentence'].astype(str)\n",
        "\n",
        "data_multi.head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3S37Y8CWI80N8KVM53U4E6JKCDC4WE</th>\n",
              "      <td>bible</td>\n",
              "      <td>seventh day sabbath yahweh god shall work son ...</td>\n",
              "      <td>seventh day</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3WGCNLZJKF877FYC1Q6COKNWTDWD11</th>\n",
              "      <td>bible</td>\n",
              "      <td>let man test own work take pride neighbor</td>\n",
              "      <td>own work</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3UOMW19E6D6WQ5TH2HDD74IVKTP5CB</th>\n",
              "      <td>bible</td>\n",
              "      <td>understanding made heaven loving kindness endu...</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36JW4WBR06KF9AXMUL4N476OMF8FHD</th>\n",
              "      <td>bible</td>\n",
              "      <td>remember god also spare according greatness lo...</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A</th>\n",
              "      <td>bible</td>\n",
              "      <td>loving kindness better life lip shall praise</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               corpus  ... complexity\n",
              "id                                     ...           \n",
              "3S37Y8CWI80N8KVM53U4E6JKCDC4WE  bible  ...   0.027778\n",
              "3WGCNLZJKF877FYC1Q6COKNWTDWD11  bible  ...   0.050000\n",
              "3UOMW19E6D6WQ5TH2HDD74IVKTP5CB  bible  ...   0.050000\n",
              "36JW4WBR06KF9AXMUL4N476OMF8FHD  bible  ...   0.050000\n",
              "3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A  bible  ...   0.075000\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iuUvPq0_4Ob"
      },
      "source": [
        "# # use if model is to be trained on both data together\n",
        "\n",
        "# data = pd.concat([data, data_multi])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shXwG0Yj-VQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5182b03a-ecac-40ee-babc-1722f3df33b4"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "  return word_to_vec_map\n",
        "\n",
        "word_to_vec_map = read_glove_vector('embeddings/glove.6B.300d.txt')\n",
        "print(len(word_to_vec_map),\" words loaded!\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwutHald-WLn"
      },
      "source": [
        "def get_embeddings(sentences, tokens):\n",
        "    token_emb = []\n",
        "    for s,t in zip(sentences, tokens):\n",
        "        \n",
        "        # fill unk by nan\n",
        "        # calculate mean over non nan embeddings\n",
        "        # fill unk by the mean embedding of sentence\n",
        "        # pad 0 vectors till max_len\n",
        "        \n",
        "        temp_emb = [ word_to_vec_map[x] if x in word_to_vec_map else np.full((300,), np.nan) for x in t.split() ]\n",
        "        \n",
        "        # calculate mean for filling null values <unk>\n",
        "        temp_sent_emb = [ word_to_vec_map[x] if x in word_to_vec_map else np.full((300,), np.nan) for x in s.split() ]\n",
        "        mean_emb = np.nanmean(np.array(temp_sent_emb), axis=0)\n",
        "        \n",
        "        # single or multi - will be converted to (1,300) \n",
        "        temp_emb = np.mean(np.array([ mean_emb if np.isnan(x[0]) else x for x in temp_emb ]), axis=0)\n",
        "\n",
        "        token_emb.append(temp_emb)\n",
        "\n",
        "    return np.array(token_emb)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDM8FtGrv3Cu"
      },
      "source": [
        "## CNN Regression Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUc4c5H8wWiz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split             \n",
        "from keras.preprocessing.text import Tokenizer                    \n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEOeEAEfwAJj"
      },
      "source": [
        "sentences_train_list = list(data['sentence'])\n",
        "complexity_train_list = list(data['complexity'])\n",
        "\n",
        "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
        "                                                sentences_train_list, complexity_train_list,  \n",
        "                                                test_size=0.25,  \n",
        "                                                random_state=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHsiKksPwilG"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "# Adding 1 because of  reserved 0 index\n",
        "vocab_size = len(tokenizer.word_index) + 1                          \n",
        "\n",
        "maxlen = 128\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zo9sbagw1vW"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "  vocab_size = len(word_index) + 1  \n",
        "  embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "  with open(filepath) as f:\n",
        "    for line in f:\n",
        "      word, *vector = line.split()\n",
        "      if word in word_index:\n",
        "        idx = word_index[word] \n",
        "        embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "  return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3JmHZHxSgc"
      },
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = create_embedding_matrix('embeddings/glove.6B.300d.txt ,tokenizer.word_index,  \n",
        "                                            embedding_dim' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH-qxn1zojp2"
      },
      "source": [
        "## **Test Single Word**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJzy1Juz_gqx"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines_ankit/single\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3iXv8sIXSyR",
        "outputId": "bd2b264e-db65-442a-c8e5-c0e0d72008dd"
      },
      "source": [
        "sentences_train_list = list(data['sentence'])\n",
        "complexity_train_list = list(data['complexity'])\n",
        "tokens_train_list = list(data['token'])\n",
        "\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9179, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXS52dlZhyXt"
      },
      "source": [
        "test_df = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_single_test_preprocessed.csv\"), index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3FLUZ7NdmHW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087b8f43-9b45-47dc-8ad0-be5afbbf5ba5"
      },
      "source": [
        "test_df['token'] = test_df['token'].astype(str)\n",
        "test_df['sentence'] = test_df['sentence'].astype(str)\n",
        "sentences_test_list = list(test_df['sentence'])\n",
        "test_tokens_list = list(test_df['token'])\n",
        "\n",
        "testdf_vectors = get_embeddings(sentences_test_list, test_tokens_list)\n",
        "testdf_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(917, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXHiacxNifhJ"
      },
      "source": [
        "# Linear Regression\n",
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6VHoYyIin98",
        "outputId": "09d596c4-3e71-4a2b-e7d8-6c9576218336"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_single_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.6715029466644609\n",
            "spearman :  0.6548482413646795\n",
            "mae      :  0.0759823204469714\n",
            "mse      :  0.009499099203375246\n",
            "r2       :  0.4130951539079504\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.6939712352149733\n",
            "spearman :  0.6731328271116146\n",
            "mae      :  0.0715689474868356\n",
            "mse      :  0.008668781235018004\n",
            "r2       :  0.46439661197178606\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.6631336571796327\n",
            "spearman :  0.6357005159629594\n",
            "mae      :  0.08355461007871447\n",
            "mse      :  0.011214615888546787\n",
            "r2       :  0.30710141339398755\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.6678429730298119\n",
            "spearman :  0.6568058055125834\n",
            "mae      :  0.07496900141336407\n",
            "mse      :  0.009234749134759981\n",
            "r2       :  0.42942810643464235\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.5207687017064077\n",
            "spearman :  0.5172088187127104\n",
            "mae      :  0.10987027960820457\n",
            "mse      :  0.02178758707478297\n",
            "r2       :  -0.3461529525135425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcbIxJtE_wrW"
      },
      "source": [
        "For file gradient_boosting_baseline.csv\n",
        "pearson  :  0.7214444729661804\n",
        "spearman :  0.6954546622318855\n",
        "mae      :  0.06718193713274725\n",
        "mse      :  0.00777120977316972\n",
        "r2       :  0.5198533483837506"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svgv6n9e-Q7I"
      },
      "source": [
        "## **Multi Word**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Z8spmk_cCb"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines_ankit/multi\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQDHP9vr-jlz"
      },
      "source": [
        "#  DO NOT run if both is being trained together\n",
        "sentences_train_list = list(data_multi['sentence'])\n",
        "complexity_train_list = list(data_multi['complexity'])\n",
        "tokens_train_list = list(data_multi['token'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccLbHMyM-jl1",
        "outputId": "889e0cb2-1efd-452a-f756-acebfca756c8"
      },
      "source": [
        "#  DO NOT run if both is being trained together\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1517, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYtjY-_T9VNG"
      },
      "source": [
        "test_df = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_multi_test_preprocessed.csv\"), index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2UTW87W9VNG"
      },
      "source": [
        "test_df['token'] = test_df['token'].astype(str)\n",
        "test_df['sentence'] = test_df['sentence'].astype(str)\n",
        "sentences_test_list = list(test_df['sentence'])\n",
        "test_tokens_list = list(test_df['token'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiM-EnF79VNH",
        "outputId": "af464dd1-c67d-4502-f72b-f61a7dded433"
      },
      "source": [
        "testdf_vectors = get_embeddings(sentences_test_list, test_tokens_list)\n",
        "testdf_vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(184, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv8DXM5X9VNH"
      },
      "source": [
        "# Linear Regression\n",
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvkkKdbS9VNJ",
        "outputId": "5cff7f76-cf32-49d6-fb63-939bb825a00f"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_multi_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.8179201155507047\n",
            "spearman :  0.8049744407871943\n",
            "mae      :  0.10626544460880245\n",
            "mse      :  0.0162353528148035\n",
            "r2       :  0.3273702640454511\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.8193283866008076\n",
            "spearman :  0.8090107910611813\n",
            "mae      :  0.10516079075843644\n",
            "mse      :  0.01603721066214149\n",
            "r2       :  0.3355792820659891\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.7941548334757821\n",
            "spearman :  0.7748241073073495\n",
            "mae      :  0.09844777180132516\n",
            "mse      :  0.014233323214324571\n",
            "r2       :  0.41031423556884616\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.8137261535536578\n",
            "spearman :  0.8074492340697415\n",
            "mae      :  0.07244008552665147\n",
            "mse      :  0.008700322647294615\n",
            "r2       :  0.6395461317210687\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.6233131383622625\n",
            "spearman :  0.5826967735152306\n",
            "mae      :  0.1111621001267914\n",
            "mse      :  0.019383115877151115\n",
            "r2       :  0.19695862090925698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnBDIaZS08B_"
      },
      "source": [
        "For file linear_regression_baseline.csv\n",
        "pearson  :  0.7384735689252496\n",
        "spearman :  0.7096751511559939\n",
        "mae      :  0.08420414291697727\n",
        "mse      :  0.011177467719053704\n",
        "r2       :  0.5369181534723191\n",
        "\n",
        "For file gradient_boosting_baseline.csv\n",
        "pearson  :  0.7870767227623038\n",
        "spearman :  0.7664566772179571\n",
        "mae      :  0.07831874126395687\n",
        "mse      :  0.009391251928283358\n",
        "r2       :  0.6109209712372773\n",
        "\n",
        "For file SVM_baseline.csv\n",
        "pearson  :  0.7747686594582374\n",
        "spearman :  0.7563503882622532\n",
        "mae      :  0.07906457106883466\n",
        "mse      :  0.009776174954316456\n",
        "r2       :  0.5949736323456092"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCS9A2TN1IcT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1wXzYgmV2Mx"
      },
      "source": [
        "## Features - load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmAPF6kVbdX8",
        "outputId": "43057f57-5277-493c-d6b8-587a672bb7f6"
      },
      "source": [
        "f1 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/extra_features/lcp_single_train_features.csv\"), index_col=0)\n",
        "f1['token'] = f1['token'].astype(str)\n",
        "f1['sentence'] = f1['sentence'].astype(str)\n",
        "f1.set_index(\"id\", inplace=True)\n",
        "\n",
        "# drop unwanted features\n",
        "f1.drop(['parse', 'lemma'], axis=1, inplace=True)\n",
        "\n",
        "print(f1.columns)\n",
        "\n",
        "f2 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/added_corpus_presence/lcp_single_train_preprocessed.csv\"), index_col=0)\n",
        "f2['token'] = f2['token'].astype(str)\n",
        "f2['sentence'] = f2['sentence'].astype(str)\n",
        "print(f2.columns)\n",
        "\n",
        "features = f1.merge(f2, on=['id','sentence', 'corpus', 'token', 'complexity'])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['sentence', 'corpus', 'token', 'complexity', 'token_length',\n",
            "       'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms',\n",
            "       'google frequency'],\n",
            "      dtype='object')\n",
            "Index(['corpus', 'sentence', 'token', 'complexity', 'biomedical', 'bible',\n",
            "       'subtitles', 'wiki', 'familarity'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "-G3zFmbnhPqB",
        "outputId": "0503aa55-3c6f-41d0-c1a8-8dfc8840007a"
      },
      "source": [
        "# fill pos nan by NN, as they are in majority\n",
        "features['pos'] = features['pos'].fillna('NN')\n",
        "features['token_length'] = features['token_length'].fillna(0)\n",
        "\n",
        "# categorical encoding\n",
        "labels = dict(features['pos'].value_counts())\n",
        "labels = { k:i for i,k in enumerate(labels)}\n",
        "labels['POS'] = len(labels)\n",
        "print(labels)\n",
        "\n",
        "\n",
        "def get_vowels(word):\n",
        "    val = 0\n",
        "    for w in word:\n",
        "        if(w in ['A', 'a', 'E', 'e', 'I', 'i', 'O', 'o', 'U','u']):\n",
        "            val+=1\n",
        "    return val\n",
        "\n",
        "features['token_vowels'] = features['token'].apply(lambda x: get_vowels(x) )\n",
        "\n",
        "\n",
        "features['pos'] = features['pos'].apply((lambda x: labels[x]))\n",
        "\n",
        "# scaler = preprocessing.StandardScaler()\n",
        "# features[['token_length', 'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms', 'google frequency', 'familarity', 'token_vowels']] =  \\\n",
        "#     scaler.fit_transform(features[['token_length', 'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms', 'google frequency', 'familarity', 'token_vowels']])\n",
        "\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'NN': 0, 'JJ': 1, 'NNP': 2, 'NNS': 3, 'VBG': 4, 'VB': 5, 'RB': 6, 'VBP': 7, 'UH': 8, 'CD': 9, 'VBN': 10, 'FW': 11, 'VBZ': 12, 'IN': 13, 'JJR': 14, 'VBD': 15, 'PRP': 16, 'GW': 17, 'MD': 18, 'JJS': 19, 'WRB': 20, 'AFX': 21, 'LS': 22, 'POS': 23}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>pos</th>\n",
              "      <th>dep num</th>\n",
              "      <th>synonyms</th>\n",
              "      <th>hypernyms</th>\n",
              "      <th>hyponyms</th>\n",
              "      <th>google frequency</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "      <th>token_vowels</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3ZLW647WALVGE8EBR50EGUBPU4P32A</th>\n",
              "      <td>behold came river seven cattle sleek fat fed m...</td>\n",
              "      <td>bible</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>173.485953</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34R0BODSP1ZBN3DVY8J8XSIY551E5C</th>\n",
              "      <td>fellow bondservant brother prophet keep word book</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>112.198857</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</th>\n",
              "      <td>man lord land said u know honest men leave one...</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>112.198857</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3BFNCI9LYKQN09BHXHH9CLSX5KP738</th>\n",
              "      <td>shimei sixteen son six daughter brother didnt ...</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>112.198857</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</th>\n",
              "      <td>put brother far</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>112.198857</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... token_vowels\n",
              "id                                                                                 ...             \n",
              "3ZLW647WALVGE8EBR50EGUBPU4P32A  behold came river seven cattle sleek fat fed m...  ...            2\n",
              "34R0BODSP1ZBN3DVY8J8XSIY551E5C  fellow bondservant brother prophet keep word book  ...            2\n",
              "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  man lord land said u know honest men leave one...  ...            2\n",
              "3BFNCI9LYKQN09BHXHH9CLSX5KP738  shimei sixteen son six daughter brother didnt ...  ...            2\n",
              "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2                                    put brother far  ...            2\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ocBaxNJ1uPD-",
        "outputId": "b4f6c0b2-d650-437b-9ee6-95fde9b156d5"
      },
      "source": [
        "multi_f1 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/extra_features/lcp_multi_train_split_features.csv\"), index_col=0)\n",
        "multi_f1['token'] = multi_f1['token'].astype(str)\n",
        "multi_f1['sentence'] = multi_f1['sentence'].astype(str)\n",
        "multi_f1.set_index(\"id\", inplace=True)\n",
        "\n",
        "# drop unwanted features\n",
        "multi_f1.drop(['parse', 'token1', 'token2', 'lemma1', 'lemma2', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
        "\n",
        "multi_f2 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/added_corpus_presence/lcp_multi_train_preprocessed.csv\"), index_col=0)\n",
        "multi_f2['token'] = multi_f2['token'].astype(str)\n",
        "multi_f2['sentence'] = multi_f2['sentence'].astype(str)\n",
        "\n",
        "multi_features = multi_f1.merge(multi_f2, on=['id','sentence', 'corpus', 'token', 'complexity'])\n",
        "multi_features.head(2)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>pos1</th>\n",
              "      <th>dep num1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>dep num2</th>\n",
              "      <th>synonyms1</th>\n",
              "      <th>hypernyms1</th>\n",
              "      <th>hyponyms1</th>\n",
              "      <th>synonyms2</th>\n",
              "      <th>hypernyms2</th>\n",
              "      <th>hyponyms2</th>\n",
              "      <th>google frequency1</th>\n",
              "      <th>google frequency2</th>\n",
              "      <th>token_vowels</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3S37Y8CWI80N8KVM53U4E6JKCDC4WE</th>\n",
              "      <td>seventh day sabbath yahweh god shall work son ...</td>\n",
              "      <td>bible</td>\n",
              "      <td>seventh day</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>JJ</td>\n",
              "      <td>0</td>\n",
              "      <td>NN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>24.522564</td>\n",
              "      <td>682.298213</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3WGCNLZJKF877FYC1Q6COKNWTDWD11</th>\n",
              "      <td>let man test own work take pride neighbor</td>\n",
              "      <td>bible</td>\n",
              "      <td>own work</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>JJ</td>\n",
              "      <td>0</td>\n",
              "      <td>NN</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1022.711588</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... familarity\n",
              "id                                                                                 ...           \n",
              "3S37Y8CWI80N8KVM53U4E6JKCDC4WE  seventh day sabbath yahweh god shall work son ...  ...        0.0\n",
              "3WGCNLZJKF877FYC1Q6COKNWTDWD11          let man test own work take pride neighbor  ...        0.0\n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "6oRx6fW5uxx1",
        "outputId": "d51d2e70-c508-4925-a641-348d947363d4"
      },
      "source": [
        "# fill pos nan by NN, as they are in majority\n",
        "multi_features['pos2'] = multi_features['pos2'].fillna('NN')\n",
        "\n",
        "multi_features['pos1'] = multi_features['pos1'].apply((lambda x: labels[x]))\n",
        "multi_features['pos2'] = multi_features['pos2'].apply((lambda x: labels[x]))\n",
        "\n",
        "# scaler = preprocessing.StandardScaler()\n",
        "# multi_features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']] =  \\\n",
        "#     scaler.fit_transform(multi_features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']])\n",
        "\n",
        "\n",
        "multi_features.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>pos1</th>\n",
              "      <th>dep num1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>dep num2</th>\n",
              "      <th>synonyms1</th>\n",
              "      <th>hypernyms1</th>\n",
              "      <th>hyponyms1</th>\n",
              "      <th>synonyms2</th>\n",
              "      <th>hypernyms2</th>\n",
              "      <th>hyponyms2</th>\n",
              "      <th>google frequency1</th>\n",
              "      <th>google frequency2</th>\n",
              "      <th>token_vowels</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3S37Y8CWI80N8KVM53U4E6JKCDC4WE</th>\n",
              "      <td>seventh day sabbath yahweh god shall work son ...</td>\n",
              "      <td>bible</td>\n",
              "      <td>seventh day</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>24.522564</td>\n",
              "      <td>682.298213</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3WGCNLZJKF877FYC1Q6COKNWTDWD11</th>\n",
              "      <td>let man test own work take pride neighbor</td>\n",
              "      <td>bible</td>\n",
              "      <td>own work</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1022.711588</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3UOMW19E6D6WQ5TH2HDD74IVKTP5CB</th>\n",
              "      <td>understanding made heaven loving kindness endu...</td>\n",
              "      <td>bible</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>339.132903</td>\n",
              "      <td>14.221491</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36JW4WBR06KF9AXMUL4N476OMF8FHD</th>\n",
              "      <td>remember god also spare according greatness lo...</td>\n",
              "      <td>bible</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>339.132903</td>\n",
              "      <td>14.221491</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A</th>\n",
              "      <td>loving kindness better life lip shall praise</td>\n",
              "      <td>bible</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>339.132903</td>\n",
              "      <td>14.221491</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... familarity\n",
              "id                                                                                 ...           \n",
              "3S37Y8CWI80N8KVM53U4E6JKCDC4WE  seventh day sabbath yahweh god shall work son ...  ...        0.0\n",
              "3WGCNLZJKF877FYC1Q6COKNWTDWD11          let man test own work take pride neighbor  ...        0.0\n",
              "3UOMW19E6D6WQ5TH2HDD74IVKTP5CB  understanding made heaven loving kindness endu...  ...        0.0\n",
              "36JW4WBR06KF9AXMUL4N476OMF8FHD  remember god also spare according greatness lo...  ...        0.0\n",
              "3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A       loving kindness better life lip shall praise  ...        0.0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "-rS4FNqV5vp1",
        "outputId": "252e6cf1-0d33-4ffa-ca78-b723ad7bcb89"
      },
      "source": [
        "# merge both single and multi features\n",
        "\n",
        "features['pos1'] = features['pos'].copy()\n",
        "features['pos2'] = features['pos'] \n",
        "\n",
        "features['dep num1'] = features['dep num'] \n",
        "features['dep num2'] = features['dep num'] \n",
        "\n",
        "features['synonyms1'] = features['synonyms'] \n",
        "features['synonyms2'] = features['synonyms'] \n",
        "\n",
        "features['hypernyms1'] = features['hypernyms'] \n",
        "features['hypernyms2'] = features['hypernyms'] \n",
        "\n",
        "features['hyponyms1'] = features['hyponyms'] \n",
        "features['hyponyms2'] = features['hyponyms'] \n",
        "\n",
        "features['google frequency1'] = features['google frequency'] \n",
        "features['google frequency2'] = features['google frequency1'] \n",
        "\n",
        "features.drop(['pos','dep num', 'synonyms', 'hyponyms', 'hypernyms', 'google frequency'], axis=1, inplace=True)\n",
        "\n",
        "features = features.append( multi_features)\n",
        "print(len(features))\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']] =  \\\n",
        "    scaler.fit_transform(features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']])\n",
        "\n",
        "features.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "      <th>token_vowels</th>\n",
              "      <th>pos1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>dep num1</th>\n",
              "      <th>dep num2</th>\n",
              "      <th>synonyms1</th>\n",
              "      <th>synonyms2</th>\n",
              "      <th>hypernyms1</th>\n",
              "      <th>hypernyms2</th>\n",
              "      <th>hyponyms1</th>\n",
              "      <th>hyponyms2</th>\n",
              "      <th>google frequency1</th>\n",
              "      <th>google frequency2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3ZLW647WALVGE8EBR50EGUBPU4P32A</th>\n",
              "      <td>behold came river seven cattle sleek fat fed m...</td>\n",
              "      <td>bible</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.797042</td>\n",
              "      <td>-0.505404</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.689858</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.248693</td>\n",
              "      <td>-0.707506</td>\n",
              "      <td>-0.831106</td>\n",
              "      <td>-0.729400</td>\n",
              "      <td>-0.754824</td>\n",
              "      <td>0.336733</td>\n",
              "      <td>0.195761</td>\n",
              "      <td>-0.333525</td>\n",
              "      <td>-0.369612</td>\n",
              "      <td>0.419993</td>\n",
              "      <td>0.466245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34R0BODSP1ZBN3DVY8J8XSIY551E5C</th>\n",
              "      <td>fellow bondservant brother prophet keep word book</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.337058</td>\n",
              "      <td>-0.505404</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.689858</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.248693</td>\n",
              "      <td>1.709990</td>\n",
              "      <td>1.365895</td>\n",
              "      <td>-0.024553</td>\n",
              "      <td>-0.063647</td>\n",
              "      <td>0.336733</td>\n",
              "      <td>0.195761</td>\n",
              "      <td>-0.168281</td>\n",
              "      <td>-0.211593</td>\n",
              "      <td>0.088143</td>\n",
              "      <td>0.097424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</th>\n",
              "      <td>man lord land said u know honest men leave one...</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>-0.337058</td>\n",
              "      <td>-0.505404</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.689858</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.248693</td>\n",
              "      <td>0.098326</td>\n",
              "      <td>-0.098772</td>\n",
              "      <td>-0.024553</td>\n",
              "      <td>-0.063647</td>\n",
              "      <td>0.336733</td>\n",
              "      <td>0.195761</td>\n",
              "      <td>-0.168281</td>\n",
              "      <td>-0.211593</td>\n",
              "      <td>0.088143</td>\n",
              "      <td>0.097424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3BFNCI9LYKQN09BHXHH9CLSX5KP738</th>\n",
              "      <td>shimei sixteen son six daughter brother didnt ...</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>-0.337058</td>\n",
              "      <td>-0.505404</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.689858</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.248693</td>\n",
              "      <td>2.515822</td>\n",
              "      <td>2.098228</td>\n",
              "      <td>-0.024553</td>\n",
              "      <td>-0.063647</td>\n",
              "      <td>0.336733</td>\n",
              "      <td>0.195761</td>\n",
              "      <td>-0.168281</td>\n",
              "      <td>-0.211593</td>\n",
              "      <td>0.088143</td>\n",
              "      <td>0.097424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</th>\n",
              "      <td>put brother far</td>\n",
              "      <td>bible</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>-0.337058</td>\n",
              "      <td>-0.505404</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.689858</td>\n",
              "      <td>-0.323568</td>\n",
              "      <td>-0.248693</td>\n",
              "      <td>0.904158</td>\n",
              "      <td>0.633561</td>\n",
              "      <td>-0.024553</td>\n",
              "      <td>-0.063647</td>\n",
              "      <td>0.336733</td>\n",
              "      <td>0.195761</td>\n",
              "      <td>-0.168281</td>\n",
              "      <td>-0.211593</td>\n",
              "      <td>0.088143</td>\n",
              "      <td>0.097424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... google frequency2\n",
              "id                                                                                 ...                  \n",
              "3ZLW647WALVGE8EBR50EGUBPU4P32A  behold came river seven cattle sleek fat fed m...  ...          0.466245\n",
              "34R0BODSP1ZBN3DVY8J8XSIY551E5C  fellow bondservant brother prophet keep word book  ...          0.097424\n",
              "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  man lord land said u know honest men leave one...  ...          0.097424\n",
              "3BFNCI9LYKQN09BHXHH9CLSX5KP738  shimei sixteen son six daughter brother didnt ...  ...          0.097424\n",
              "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2                                    put brother far  ...          0.097424\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TIJwE4UsGOg"
      },
      "source": [
        "## Test with features - single"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLEjoKSBwkS0",
        "outputId": "28a1f369-0fb0-41b2-a2e5-9c94e1c55d83"
      },
      "source": [
        "sentences_train_list = list(features['sentence'])\n",
        "complexity_train_list = list(features['complexity'])\n",
        "tokens_train_list = list(features['token'])\n",
        "\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)\n",
        "\n",
        "# f_vectors = features[['token_length', 'token_vowels', 'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms', 'google frequency', 'biomedical', 'bible', 'subtitles', 'wiki', 'familarity']].values\n",
        "# or \n",
        "\n",
        "f_vectors = features[['token_length', 'token_vowels', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', \n",
        "                        'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', \n",
        "                        'google frequency1', 'google frequency2', \n",
        "                        'biomedical', 'bible', 'subtitles', 'wiki', 'familarity']].values\n",
        "\n",
        "print(f_vectors.shape)\n",
        "vectors = np.concatenate((vectors, f_vectors), axis=1)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9179, 300)\n",
            "(9179, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38GMvczOV4ES"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines_ankit/features/single\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "_LPMEPl1ioxd",
        "outputId": "bb6f419c-6ae1-408b-9e92-b0d7a52695b4"
      },
      "source": [
        "test_f1 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/extra_features/lcp_single_test_features.csv\"), index_col=0)\n",
        "test_f1['token'] = test_f1['token'].astype(str)\n",
        "test_f1['sentence'] = test_f1['sentence'].astype(str)\n",
        "test_f1.set_index(\"id\", inplace=True)\n",
        "\n",
        "# drop unwanted features\n",
        "test_f1.drop(['parse', 'lemma'], axis=1, inplace=True)\n",
        "\n",
        "test_f2 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/added_corpus_presence/lcp_single_test_preprocessed.csv\"), index_col=0)\n",
        "test_f2['token'] = test_f2['token'].astype(str)\n",
        "test_f2['sentence'] = test_f2['sentence'].astype(str)\n",
        "\n",
        "test_features = test_f1.merge(test_f2, on=['id','sentence', 'corpus', 'token'])\n",
        "test_features.head()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>pos</th>\n",
              "      <th>dep num</th>\n",
              "      <th>synonyms</th>\n",
              "      <th>hypernyms</th>\n",
              "      <th>hyponyms</th>\n",
              "      <th>google frequency</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39TX062QX1OHFOH8FUL76K5L7D3X3S</th>\n",
              "      <td>speak much prince world come nothing</td>\n",
              "      <td>bible</td>\n",
              "      <td>prince</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>57.555460</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3CIS7GGG65JS8I3AZ9RG54AE4MUUEA</th>\n",
              "      <td>house shall turned others field wife together ...</td>\n",
              "      <td>bible</td>\n",
              "      <td>inhabitant</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>1.907882</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379OL9DBSSESUVWY1Z8JGBFG9BTY92</th>\n",
              "      <td>stranger terrible nation cut left mountain val...</td>\n",
              "      <td>bible</td>\n",
              "      <td>bough</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>NN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.513619</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3DFYDSXB2W00JYP2DA272KN69UQUJV</th>\n",
              "      <td>sharpen tongue like sword aim arrow deadly word</td>\n",
              "      <td>bible</td>\n",
              "      <td>arrow</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>22.707380</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31YWE12TE0CZG7IVH6OXJ1H1CFPX7X</th>\n",
              "      <td>obey leader submit watch behalf soul give acco...</td>\n",
              "      <td>bible</td>\n",
              "      <td>account</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>216.439551</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... familarity\n",
              "id                                                                                 ...           \n",
              "39TX062QX1OHFOH8FUL76K5L7D3X3S               speak much prince world come nothing  ...          0\n",
              "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA  house shall turned others field wife together ...  ...          0\n",
              "379OL9DBSSESUVWY1Z8JGBFG9BTY92  stranger terrible nation cut left mountain val...  ...          0\n",
              "3DFYDSXB2W00JYP2DA272KN69UQUJV    sharpen tongue like sword aim arrow deadly word  ...          0\n",
              "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X  obey leader submit watch behalf soul give acco...  ...          0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJTjX8NBioyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "a7fc2aff-1b3b-43cb-884a-9943a8ec9bcd"
      },
      "source": [
        "# # fill pos nan by NN, as they are in majority\n",
        "# test_features['pos'] = test_features['pos'].fillna('NN')\n",
        "\n",
        "# # categorical encoding\n",
        "# test_features['pos'] = test_features['pos'].apply((lambda x: labels[x]))\n",
        "\n",
        "# def get_vowels(word):\n",
        "#     val = 0\n",
        "#     for w in word:\n",
        "#         if(w in ['A', 'a', 'E', 'e', 'I', 'i', 'O', 'o', 'U','u']):\n",
        "#             val+=1\n",
        "#     return val\n",
        "\n",
        "# test_features['token_vowels'] = test_features['token'].apply(lambda x: get_vowels(x) )\n",
        "\n",
        "# test_features[['token_length', 'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms', 'google frequency', 'familarity', 'token_vowels']] =  \\\n",
        "#     scaler.transform(test_features[['token_length', 'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms', 'google frequency', 'familarity', 'token_vowels']])\n",
        "\n",
        "# ##########  for all features\n",
        "\n",
        "# fill pos nan by NN, as they are in majority\n",
        "test_features['pos'] = test_features['pos'].fillna('NN')\n",
        "test_features['token_length'] = test_features['token_length'].fillna(0)\n",
        "\n",
        "test_features['pos'] = test_features['pos'].apply((lambda x: labels[x]))\n",
        "\n",
        "def get_vowels(word):\n",
        "    val = 0\n",
        "    for w in word:\n",
        "        if(w in ['A', 'a', 'E', 'e', 'I', 'i', 'O', 'o', 'U','u']):\n",
        "            val+=1\n",
        "    return val\n",
        "\n",
        "test_features['token_vowels'] = test_features['token'].apply(lambda x: get_vowels(x) )\n",
        "\n",
        "test_features['pos1'] = test_features['pos'].copy()\n",
        "test_features['pos2'] = test_features['pos'] \n",
        "\n",
        "test_features['dep num1'] = test_features['dep num'] \n",
        "test_features['dep num2'] = test_features['dep num'] \n",
        "\n",
        "test_features['synonyms1'] = test_features['synonyms'] \n",
        "test_features['synonyms2'] = test_features['synonyms'] \n",
        "\n",
        "test_features['hypernyms1'] = test_features['hypernyms'] \n",
        "test_features['hypernyms2'] = test_features['hypernyms'] \n",
        "\n",
        "test_features['hyponyms1'] = test_features['hyponyms'] \n",
        "test_features['hyponyms2'] = test_features['hyponyms'] \n",
        "\n",
        "test_features['google frequency1'] = test_features['google frequency'] \n",
        "test_features['google frequency2'] = test_features['google frequency'] \n",
        "\n",
        "test_features.drop(['pos','dep num', 'synonyms', 'hyponyms', 'hypernyms', 'google frequency'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "test_features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']] =  \\\n",
        "    scaler.fit_transform(test_features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']])\n",
        "\n",
        "test_features.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "      <th>token_vowels</th>\n",
              "      <th>pos1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>dep num1</th>\n",
              "      <th>dep num2</th>\n",
              "      <th>synonyms1</th>\n",
              "      <th>synonyms2</th>\n",
              "      <th>hypernyms1</th>\n",
              "      <th>hypernyms2</th>\n",
              "      <th>hyponyms1</th>\n",
              "      <th>hyponyms2</th>\n",
              "      <th>google frequency1</th>\n",
              "      <th>google frequency2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39TX062QX1OHFOH8FUL76K5L7D3X3S</th>\n",
              "      <td>speak much prince world come nothing</td>\n",
              "      <td>bible</td>\n",
              "      <td>prince</td>\n",
              "      <td>-0.359207</td>\n",
              "      <td>-1.209359</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.569449</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.786155</td>\n",
              "      <td>-0.786155</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.429456</td>\n",
              "      <td>0.429456</td>\n",
              "      <td>-0.266096</td>\n",
              "      <td>-0.266096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3CIS7GGG65JS8I3AZ9RG54AE4MUUEA</th>\n",
              "      <td>house shall turned others field wife together ...</td>\n",
              "      <td>bible</td>\n",
              "      <td>inhabitant</td>\n",
              "      <td>1.207464</td>\n",
              "      <td>1.600562</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.029891</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.786155</td>\n",
              "      <td>-0.786155</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>2.359902</td>\n",
              "      <td>2.359902</td>\n",
              "      <td>-0.593957</td>\n",
              "      <td>-0.593957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379OL9DBSSESUVWY1Z8JGBFG9BTY92</th>\n",
              "      <td>stranger terrible nation cut left mountain val...</td>\n",
              "      <td>bible</td>\n",
              "      <td>bough</td>\n",
              "      <td>-0.750874</td>\n",
              "      <td>-1.209359</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.569449</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>0.67311</td>\n",
              "      <td>0.67311</td>\n",
              "      <td>-0.786155</td>\n",
              "      <td>-0.786155</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>-0.535767</td>\n",
              "      <td>-0.535767</td>\n",
              "      <td>-0.596279</td>\n",
              "      <td>-0.596279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3DFYDSXB2W00JYP2DA272KN69UQUJV</th>\n",
              "      <td>sharpen tongue like sword aim arrow deadly word</td>\n",
              "      <td>bible</td>\n",
              "      <td>arrow</td>\n",
              "      <td>-0.750874</td>\n",
              "      <td>-0.272719</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.569449</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.597733</td>\n",
              "      <td>-0.597733</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>-0.535767</td>\n",
              "      <td>-0.535767</td>\n",
              "      <td>-0.471412</td>\n",
              "      <td>-0.471412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31YWE12TE0CZG7IVH6OXJ1H1CFPX7X</th>\n",
              "      <td>obey leader submit watch behalf soul give acco...</td>\n",
              "      <td>bible</td>\n",
              "      <td>account</td>\n",
              "      <td>0.032461</td>\n",
              "      <td>-0.272719</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.230221</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.215025</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>-0.84719</td>\n",
              "      <td>1.663337</td>\n",
              "      <td>1.663337</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.23992</td>\n",
              "      <td>0.139889</td>\n",
              "      <td>0.139889</td>\n",
              "      <td>0.670006</td>\n",
              "      <td>0.670006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... google frequency2\n",
              "id                                                                                 ...                  \n",
              "39TX062QX1OHFOH8FUL76K5L7D3X3S               speak much prince world come nothing  ...         -0.266096\n",
              "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA  house shall turned others field wife together ...  ...         -0.593957\n",
              "379OL9DBSSESUVWY1Z8JGBFG9BTY92  stranger terrible nation cut left mountain val...  ...         -0.596279\n",
              "3DFYDSXB2W00JYP2DA272KN69UQUJV    sharpen tongue like sword aim arrow deadly word  ...         -0.471412\n",
              "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X  obey leader submit watch behalf soul give acco...  ...          0.670006\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RV33imHjy2j",
        "outputId": "d3231b80-4cf3-4af9-b90d-fed37d76125d"
      },
      "source": [
        "sentences_test_list = list(test_features['sentence'])\n",
        "test_tokens_list = list(test_features['token'])\n",
        "\n",
        "test_vectors = get_embeddings(sentences_test_list, test_tokens_list)\n",
        "print(test_vectors.shape)\n",
        "\n",
        "# test_f_vectors = test_features[['token_length', 'token_vowels', 'syllables', 'pos', 'dep num', 'synonyms', 'hypernyms', 'hyponyms', 'google frequency', 'biomedical', 'bible', 'subtitles', 'wiki', 'familarity']].values\n",
        "\n",
        "test_f_vectors = test_features[['token_length', 'token_vowels', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', \n",
        "                        'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', \n",
        "                        'google frequency1', 'google frequency2', \n",
        "                        'biomedical', 'bible', 'subtitles', 'wiki', 'familarity']].values\n",
        "\n",
        "test_vectors = np.concatenate((test_vectors, test_f_vectors), axis=1)\n",
        "print(test_vectors.shape)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(917, 300)\n",
            "(917, 320)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvPffbjPjIBi"
      },
      "source": [
        "# Linear Regression\n",
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzQ_4UNLjVJB",
        "outputId": "bc6b82f2-680d-4ab5-c533-180faa31b5bf"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_single_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.6764732930844866\n",
            "spearman :  0.6760017156397601\n",
            "mae      :  0.07569338580364902\n",
            "mse      :  0.009511516322174056\n",
            "r2       :  0.4123279582990307\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.7015786271547141\n",
            "spearman :  0.672954947440128\n",
            "mae      :  0.07348020617004901\n",
            "mse      :  0.009052928685933177\n",
            "r2       :  0.4406619403225088\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.6829921537603776\n",
            "spearman :  0.6725387317487636\n",
            "mae      :  0.0788341859096584\n",
            "mse      :  0.010327774663127768\n",
            "r2       :  0.3618951787573066\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.6968593439567711\n",
            "spearman :  0.6843007666696466\n",
            "mae      :  0.07361390870122693\n",
            "mse      :  0.008702552238726511\n",
            "r2       :  0.46231005983567686\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.5446037367508759\n",
            "spearman :  0.526313892693398\n",
            "mae      :  0.1081767212887482\n",
            "mse      :  0.01973212019436534\n",
            "r2       :  -0.2191552817585971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYQs4natxevq"
      },
      "source": [
        "## Test with features - multi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9LuuTs3xevr",
        "outputId": "9fed9dd5-bb43-4455-98a6-2c11e6e863b3"
      },
      "source": [
        "sentences_train_list = list(multi_features['sentence'])\n",
        "complexity_train_list = list(multi_features['complexity'])\n",
        "tokens_train_list = list(multi_features['token'])\n",
        "\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)\n",
        "\n",
        "f_vectors = multi_features[['token_length', 'token_vowels', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', \n",
        "                        'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', \n",
        "                        'google frequency1', 'google frequency2', \n",
        "                        'biomedical', 'bible', 'subtitles', 'wiki', 'familarity']].values\n",
        "print(f_vectors.shape)\n",
        "vectors = np.concatenate((vectors, f_vectors), axis=1)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1517, 300)\n",
            "(1517, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTgM0RNsxevu"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines_ankit/features/multi\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "yTAotilTxevv",
        "outputId": "bdca224a-38cf-400a-af96-2775dca0c8c9"
      },
      "source": [
        "test_multi_f1 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/extra_features/lcp_multi_test_split_features.csv\"), index_col=0)\n",
        "test_multi_f1['token'] = test_multi_f1['token'].astype(str)\n",
        "test_multi_f1['sentence'] = test_multi_f1['sentence'].astype(str)\n",
        "test_multi_f1.set_index(\"id\", inplace=True)\n",
        "\n",
        "# drop unwanted features\n",
        "test_multi_f1.drop(['parse', 'token1', 'token2', 'lemma1', 'lemma2', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
        "\n",
        "test_multi_f2 = pd.read_csv(os.path.join(FOLDER_PATH, \"data/added_corpus_presence/lcp_multi_test_preprocessed.csv\"), index_col=0)\n",
        "test_multi_f2['token'] = test_multi_f2['token'].astype(str)\n",
        "test_multi_f2['sentence'] = test_multi_f2['sentence'].astype(str)\n",
        "\n",
        "test_multi_features = test_multi_f1.merge(test_multi_f2, on=['id','sentence', 'corpus', 'token'])\n",
        "test_multi_features['token'] = test_multi_f2['token'].astype(str)\n",
        "test_multi_features.head(2)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>pos1</th>\n",
              "      <th>dep num1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>dep num2</th>\n",
              "      <th>synonyms1</th>\n",
              "      <th>hypernyms1</th>\n",
              "      <th>hyponyms1</th>\n",
              "      <th>synonyms2</th>\n",
              "      <th>hypernyms2</th>\n",
              "      <th>hyponyms2</th>\n",
              "      <th>google frequency1</th>\n",
              "      <th>google frequency2</th>\n",
              "      <th>token_vowels</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3A9LA2FRWSEW9WO7UFA9AE6VQK3XHL</th>\n",
              "      <td>come intending bring bound chief priest</td>\n",
              "      <td>bible</td>\n",
              "      <td>chief priest</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>JJ</td>\n",
              "      <td>0</td>\n",
              "      <td>NN</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.121551</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302U8RURJZ1WF35NXY44RD66WL4NVH</th>\n",
              "      <td>day lord take away beauty anklet headband cres...</td>\n",
              "      <td>bible</td>\n",
              "      <td>crescent necklace</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>NN</td>\n",
              "      <td>1</td>\n",
              "      <td>NN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.830131</td>\n",
              "      <td>4.021996</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... familarity\n",
              "id                                                                                 ...           \n",
              "3A9LA2FRWSEW9WO7UFA9AE6VQK3XHL            come intending bring bound chief priest  ...        0.0\n",
              "302U8RURJZ1WF35NXY44RD66WL4NVH  day lord take away beauty anklet headband cres...  ...        0.0\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi5GeQE0xevx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "aa2ef41d-508d-4f6d-97d7-82da793cb9d7"
      },
      "source": [
        "# fill pos nan by NN, as they are in majority\n",
        "test_multi_features['pos2'] = test_multi_features['pos2'].fillna('NN')\n",
        "\n",
        "test_multi_features['pos1'] = test_multi_features['pos1'].apply((lambda x: labels[x]))\n",
        "test_multi_features['pos2'] = test_multi_features['pos2'].apply((lambda x: labels[x]))\n",
        "\n",
        "test_multi_features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']] =  \\\n",
        "    scaler.fit_transform(test_multi_features[['token_length', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', 'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', 'google frequency1', 'google frequency2', 'familarity', 'token_vowels']])\n",
        "\n",
        "\n",
        "test_multi_features.head()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>corpus</th>\n",
              "      <th>token</th>\n",
              "      <th>token_length</th>\n",
              "      <th>syllables</th>\n",
              "      <th>pos1</th>\n",
              "      <th>dep num1</th>\n",
              "      <th>pos2</th>\n",
              "      <th>dep num2</th>\n",
              "      <th>synonyms1</th>\n",
              "      <th>hypernyms1</th>\n",
              "      <th>hyponyms1</th>\n",
              "      <th>synonyms2</th>\n",
              "      <th>hypernyms2</th>\n",
              "      <th>hyponyms2</th>\n",
              "      <th>google frequency1</th>\n",
              "      <th>google frequency2</th>\n",
              "      <th>token_vowels</th>\n",
              "      <th>biomedical</th>\n",
              "      <th>bible</th>\n",
              "      <th>subtitles</th>\n",
              "      <th>wiki</th>\n",
              "      <th>familarity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3A9LA2FRWSEW9WO7UFA9AE6VQK3XHL</th>\n",
              "      <td>come intending bring bound chief priest</td>\n",
              "      <td>bible</td>\n",
              "      <td>chief priest</td>\n",
              "      <td>-0.901199</td>\n",
              "      <td>-1.561702</td>\n",
              "      <td>-0.007544</td>\n",
              "      <td>-0.303363</td>\n",
              "      <td>-0.179239</td>\n",
              "      <td>0.195616</td>\n",
              "      <td>-0.150640</td>\n",
              "      <td>0.803614</td>\n",
              "      <td>1.337977</td>\n",
              "      <td>-0.630931</td>\n",
              "      <td>3.91578</td>\n",
              "      <td>0.010441</td>\n",
              "      <td>-0.368197</td>\n",
              "      <td>-0.306098</td>\n",
              "      <td>-0.946411</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302U8RURJZ1WF35NXY44RD66WL4NVH</th>\n",
              "      <td>day lord take away beauty anklet headband cres...</td>\n",
              "      <td>bible</td>\n",
              "      <td>crescent necklace</td>\n",
              "      <td>0.281544</td>\n",
              "      <td>-0.569118</td>\n",
              "      <td>-0.701592</td>\n",
              "      <td>1.291460</td>\n",
              "      <td>-0.179239</td>\n",
              "      <td>0.195616</td>\n",
              "      <td>-0.564339</td>\n",
              "      <td>0.803614</td>\n",
              "      <td>-0.377617</td>\n",
              "      <td>-0.814620</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.212299</td>\n",
              "      <td>-0.354034</td>\n",
              "      <td>-0.554398</td>\n",
              "      <td>-0.444568</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3UDTAB6HH6ZVX00DTRXAOJLWX0B094</th>\n",
              "      <td>unclean shall take ash burning sin offering ru...</td>\n",
              "      <td>bible</td>\n",
              "      <td>sin offering</td>\n",
              "      <td>-0.901199</td>\n",
              "      <td>-0.569118</td>\n",
              "      <td>-0.701592</td>\n",
              "      <td>4.481106</td>\n",
              "      <td>6.102647</td>\n",
              "      <td>-0.470928</td>\n",
              "      <td>0.676757</td>\n",
              "      <td>0.803614</td>\n",
              "      <td>-0.206058</td>\n",
              "      <td>1.940711</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.295826</td>\n",
              "      <td>-0.216363</td>\n",
              "      <td>0.229547</td>\n",
              "      <td>-0.946411</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3L2OEKSTW9ASGQDOW725GFK5P77Y8D</th>\n",
              "      <td>precious treasure oil dwelling wise foolish ma...</td>\n",
              "      <td>bible</td>\n",
              "      <td>precious treasure</td>\n",
              "      <td>0.281544</td>\n",
              "      <td>-0.569118</td>\n",
              "      <td>-0.007544</td>\n",
              "      <td>-0.303363</td>\n",
              "      <td>-0.179239</td>\n",
              "      <td>-0.470928</td>\n",
              "      <td>0.056209</td>\n",
              "      <td>-1.141978</td>\n",
              "      <td>-0.377617</td>\n",
              "      <td>0.103824</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.184456</td>\n",
              "      <td>-0.300091</td>\n",
              "      <td>-0.479155</td>\n",
              "      <td>1.060962</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39N6W9XWRDN795J6F5ET8S13DQKYGT</th>\n",
              "      <td>long god shall adversary reproach</td>\n",
              "      <td>bible</td>\n",
              "      <td>adversary reproach</td>\n",
              "      <td>0.518093</td>\n",
              "      <td>0.423467</td>\n",
              "      <td>-0.701592</td>\n",
              "      <td>-0.303363</td>\n",
              "      <td>-0.179239</td>\n",
              "      <td>1.528705</td>\n",
              "      <td>-0.771188</td>\n",
              "      <td>0.803614</td>\n",
              "      <td>0.308621</td>\n",
              "      <td>-0.447242</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-0.240141</td>\n",
              "      <td>-0.351906</td>\n",
              "      <td>-0.547828</td>\n",
              "      <td>0.057276</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                         sentence  ... familarity\n",
              "id                                                                                 ...           \n",
              "3A9LA2FRWSEW9WO7UFA9AE6VQK3XHL            come intending bring bound chief priest  ...        0.0\n",
              "302U8RURJZ1WF35NXY44RD66WL4NVH  day lord take away beauty anklet headband cres...  ...        0.0\n",
              "3UDTAB6HH6ZVX00DTRXAOJLWX0B094  unclean shall take ash burning sin offering ru...  ...        0.0\n",
              "3L2OEKSTW9ASGQDOW725GFK5P77Y8D  precious treasure oil dwelling wise foolish ma...  ...        0.0\n",
              "39N6W9XWRDN795J6F5ET8S13DQKYGT                  long god shall adversary reproach  ...        0.0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j18I8X1fxevy",
        "outputId": "fac38eeb-83a0-4375-a0b1-db5ab5a96529"
      },
      "source": [
        "sentences_test_list = list(test_multi_features['sentence'])\n",
        "test_tokens_list = list(test_multi_features['token'])\n",
        "\n",
        "test_vectors = get_embeddings(sentences_test_list, test_tokens_list)\n",
        "print(test_vectors.shape)\n",
        "\n",
        "test_f_vectors = test_multi_features[['token_length', 'token_vowels', 'syllables', 'pos1', 'pos2', 'dep num1', 'dep num2', \n",
        "                        'synonyms1', 'synonyms2', 'hypernyms1', 'hypernyms2', 'hyponyms1', 'hyponyms2', \n",
        "                        'google frequency1', 'google frequency2', \n",
        "                        'biomedical', 'bible', 'subtitles', 'wiki', 'familarity']].values\n",
        "test_vectors = np.concatenate((test_vectors, test_f_vectors), axis=1)\n",
        "print(test_vectors.shape)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(184, 300)\n",
            "(184, 320)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTMHt6NNxev2"
      },
      "source": [
        "# Linear Regression\n",
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_multi_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_multi_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_multi_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_multi_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(test_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_multi_features.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-K2hsDwxev3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3328df6a-fce8-4e6a-9645-319448131de6"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_multi_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.73181025788052\n",
            "spearman :  0.706710151394026\n",
            "mae      :  0.08622353323462664\n",
            "mse      :  0.01143825876694363\n",
            "r2       :  0.5261135953156546\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.7919895516580935\n",
            "spearman :  0.7663306747668398\n",
            "mae      :  0.07848888431095036\n",
            "mse      :  0.009499547922764287\n",
            "r2       :  0.606434274397143\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.8032811552045976\n",
            "spearman :  0.7729281948209605\n",
            "mae      :  0.0811253219565396\n",
            "mse      :  0.009900449092772618\n",
            "r2       :  0.589824961916992\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.6801334456449308\n",
            "spearman :  0.6922099218449158\n",
            "mae      :  0.11964508647478064\n",
            "mse      :  0.022019511294338164\n",
            "r2       :  0.0877329099830747\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.40296635924446544\n",
            "spearman :  0.4067828297544516\n",
            "mae      :  0.19860332251870674\n",
            "mse      :  0.06018139513600453\n",
            "r2       :  -1.49331174883969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vznfgjXTkJjf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}