{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ACPhKHqRyuby",
        "AUaDuIkPy_bT",
        "be6X9hcEzOSn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACPhKHqRyuby"
      },
      "source": [
        "## Initial Setup - Imports and Downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0RojGMRyMi-",
        "outputId": "d854ee14-0c7b-43fd-ed38-27d2983a8094"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efMuzwW5yjN9",
        "outputId": "59bf0245-d378-4239-8e97-ae9fab14b3bf"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d embeddings"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 06:24:16--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-04-12 06:24:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-04-12 06:24:17--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.94MB/s    in 2m 40s  \n",
            "\n",
            "2021-04-12 06:26:57 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: embeddings/glove.6B.50d.txt  \n",
            "  inflating: embeddings/glove.6B.100d.txt  \n",
            "  inflating: embeddings/glove.6B.200d.txt  \n",
            "  inflating: embeddings/glove.6B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBZsjocky1Gi"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMS4PuEy1ev"
      },
      "source": [
        "FOLDER_PATH = \"/content/drive/MyDrive/CS60075-Team28-Task-1\"\n",
        "DATA_FOLDER = os.path.join(FOLDER_PATH,\"data/preprocessed\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSvgOs0sy6Dh"
      },
      "source": [
        "# import evaluate function\n",
        "import sys\n",
        "sys.path.append(FOLDER_PATH)\n",
        "from eval import evaluate"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUaDuIkPy_bT"
      },
      "source": [
        "## Getting Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "oKDk-_GEy7_D",
        "outputId": "29faba09-5511-4ef6-a08e-7af99c0ae4ef"
      },
      "source": [
        "data = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_single_train_preprocessed.csv\"), index_col=0)\n",
        "data['token'] = data['token'].astype(str)\n",
        "data['sentence'] = data['sentence'].astype(str)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3ZLW647WALVGE8EBR50EGUBPU4P32A</th>\n",
              "      <td>bible</td>\n",
              "      <td>behold came river seven cattle sleek fat fed m...</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34R0BODSP1ZBN3DVY8J8XSIY551E5C</th>\n",
              "      <td>bible</td>\n",
              "      <td>fellow bondservant brother prophet keep word book</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</th>\n",
              "      <td>bible</td>\n",
              "      <td>man lord land said u know honest men leave one...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3BFNCI9LYKQN09BHXHH9CLSX5KP738</th>\n",
              "      <td>bible</td>\n",
              "      <td>shimei sixteen son six daughter brother didnt ...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</th>\n",
              "      <td>bible</td>\n",
              "      <td>put brother far</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.263889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               corpus  ... complexity\n",
              "id                                     ...           \n",
              "3ZLW647WALVGE8EBR50EGUBPU4P32A  bible  ...   0.000000\n",
              "34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible  ...   0.000000\n",
              "3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible  ...   0.050000\n",
              "3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible  ...   0.150000\n",
              "3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible  ...   0.263889\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "BglpItt3zCuI",
        "outputId": "aa7d32f7-f650-4b8a-f1a2-cf8fa266e2c8"
      },
      "source": [
        "data_multi = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_multi_train_preprocessed.csv\"), index_col=0)\n",
        "data_multi['token'] = data_multi['token'].astype(str)\n",
        "data_multi['sentence'] = data_multi['sentence'].astype(str)\n",
        "\n",
        "data_multi.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3S37Y8CWI80N8KVM53U4E6JKCDC4WE</th>\n",
              "      <td>bible</td>\n",
              "      <td>seventh day sabbath yahweh god shall work son ...</td>\n",
              "      <td>seventh day</td>\n",
              "      <td>0.027778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3WGCNLZJKF877FYC1Q6COKNWTDWD11</th>\n",
              "      <td>bible</td>\n",
              "      <td>let man test own work take pride neighbor</td>\n",
              "      <td>own work</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3UOMW19E6D6WQ5TH2HDD74IVKTP5CB</th>\n",
              "      <td>bible</td>\n",
              "      <td>understanding made heaven loving kindness endu...</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36JW4WBR06KF9AXMUL4N476OMF8FHD</th>\n",
              "      <td>bible</td>\n",
              "      <td>remember god also spare according greatness lo...</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A</th>\n",
              "      <td>bible</td>\n",
              "      <td>loving kindness better life lip shall praise</td>\n",
              "      <td>loving kindness</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               corpus  ... complexity\n",
              "id                                     ...           \n",
              "3S37Y8CWI80N8KVM53U4E6JKCDC4WE  bible  ...   0.027778\n",
              "3WGCNLZJKF877FYC1Q6COKNWTDWD11  bible  ...   0.050000\n",
              "3UOMW19E6D6WQ5TH2HDD74IVKTP5CB  bible  ...   0.050000\n",
              "36JW4WBR06KF9AXMUL4N476OMF8FHD  bible  ...   0.050000\n",
              "3HRWUH63QU2FH9Q8R7MRNFC7JX2N5A  bible  ...   0.075000\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be6X9hcEzOSn"
      },
      "source": [
        "## Functions to Read GloVe Embeddings and Extract them According to sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dWQIdr5zEeP",
        "outputId": "5c0717d7-cbcd-4819-cf45-10f5b878d28a"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "  return word_to_vec_map\n",
        "\n",
        "word_to_vec_map = read_glove_vector('embeddings/glove.6B.300d.txt')\n",
        "print(len(word_to_vec_map),\" words loaded!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4_p1cvuzaj3"
      },
      "source": [
        "def get_embeddings(sentences, tokens):\n",
        "    token_emb = []\n",
        "    for s,t in zip(sentences, tokens):\n",
        "        \n",
        "        # fill unk by nan\n",
        "        # calculate mean over non nan embeddings\n",
        "        # fill unk by the mean embedding of sentence\n",
        "        # pad 0 vectors till max_len\n",
        "        \n",
        "        temp_emb = [ word_to_vec_map[x] if x in word_to_vec_map else np.full((300,), np.nan) for x in t.split() ]\n",
        "        \n",
        "        # calculate mean for filling null values <unk>\n",
        "        temp_sent_emb = [ word_to_vec_map[x] if x in word_to_vec_map else np.full((300,), np.nan) for x in s.split() ]\n",
        "        mean_emb = np.nanmean(np.array(temp_sent_emb), axis=0)\n",
        "        \n",
        "        # single or multi - will be converted to (1,300) \n",
        "        temp_emb = np.mean(np.array([ mean_emb if np.isnan(x[0]) else x for x in temp_emb ]), axis=0)\n",
        "\n",
        "        token_emb.append(temp_emb)\n",
        "\n",
        "    return np.array(token_emb)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEG4MZPzcuH"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDXb4VHzj5T"
      },
      "source": [
        "## Testing Single Word Complexity Predictions - with Single Token Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KSfjoy16j9S"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines/single\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPAkkrAM0WML",
        "outputId": "dae39eeb-a113-4064-e145-31987758c94b"
      },
      "source": [
        "sentences_train_list = list(data['sentence'])\n",
        "complexity_train_list = list(data['complexity'])\n",
        "tokens_train_list = list(data['token'])\n",
        "\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7662, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJuH6kz8zoym"
      },
      "source": [
        "test_df = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_single_test_preprocessed.csv\"), index_col=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4-zCprV0MdN",
        "outputId": "8fa5d98b-08c1-484e-95be-7fa77e1ce6de"
      },
      "source": [
        "test_df['token'] = test_df['token'].astype(str)\n",
        "test_df['sentence'] = test_df['sentence'].astype(str)\n",
        "sentences_test_list = list(test_df['sentence'])\n",
        "test_tokens_list = list(test_df['token'])\n",
        "\n",
        "testdf_vectors = get_embeddings(sentences_test_list, test_tokens_list)\n",
        "testdf_vectors.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(917, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ApOJjDz0NN-"
      },
      "source": [
        "# Linear Regression\n",
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPkcqXNP0Ry8",
        "outputId": "af45e5a6-3b79-4deb-c23b-8129cba861d5"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_single_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.6817130060790865\n",
            "spearman :  0.6622243983222191\n",
            "mae      :  0.0725450964271907\n",
            "mse      :  0.008759716679890811\n",
            "r2       :  0.45877813677379853\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.7203520903570985\n",
            "spearman :  0.6948938413555582\n",
            "mae      :  0.06731888763261062\n",
            "mse      :  0.007795421637461341\n",
            "r2       :  0.5183574106972986\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.6777051422207718\n",
            "spearman :  0.6451366278370756\n",
            "mae      :  0.0718233174638877\n",
            "mse      :  0.00891662105013616\n",
            "r2       :  0.4490837506748203\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.7097033380749598\n",
            "spearman :  0.6839183037224942\n",
            "mae      :  0.07039859014661132\n",
            "mse      :  0.008047758067602407\n",
            "r2       :  0.5027667246201666\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.5156106888626774\n",
            "spearman :  0.46423932585188654\n",
            "mae      :  0.10786861350295623\n",
            "mse      :  0.01897024918777512\n",
            "r2       :  -0.17208284085746972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zZNSMDwX0dCE",
        "outputId": "ab464032-8f3a-4854-e492-ea010ae4ac7c"
      },
      "source": [
        "'''\n",
        "For file gradient_boosting_baseline.csv\n",
        "pearson  :  0.7203520903570985\n",
        "spearman :  0.6948938413555582\n",
        "mae      :  0.06731888763261062\n",
        "mse      :  0.007795421637461341\n",
        "r2       :  0.5183574106972986\n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFor file gradient_boosting_baseline.csv\\npearson  :  0.7203520903570985\\nspearman :  0.6948938413555582\\nmae      :  0.06731888763261062\\nmse      :  0.007795421637461341\\nr2       :  0.5183574106972986\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Fx047u51nT"
      },
      "source": [
        "## Testing Single Word Complexity Predictions - with Single + Multi Token Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DGtxl0C6mId"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines/single\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef8m19g_5_lM"
      },
      "source": [
        "data = pd.concat([data, data_multi])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er0xkIfW6AXs",
        "outputId": "ef3c10d5-3f3d-43ba-e269-dcdbf03d5a71"
      },
      "source": [
        "sentences_train_list = list(data['sentence'])\n",
        "complexity_train_list = list(data['complexity'])\n",
        "tokens_train_list = list(data['token'])\n",
        "\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9179, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INoLovAZ6FjL"
      },
      "source": [
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Je-wcwp6MzU",
        "outputId": "74746c6c-56c8-453c-b460-0d9a3fd9510d"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_single_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.6715029466644609\n",
            "spearman :  0.6548482413646795\n",
            "mae      :  0.0759823204469714\n",
            "mse      :  0.009499099203375246\n",
            "r2       :  0.4130951539079504\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.6911351486877488\n",
            "spearman :  0.6707113273501418\n",
            "mae      :  0.07188171267210111\n",
            "mse      :  0.008743365608190055\n",
            "r2       :  0.459788392905934\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.651843952414161\n",
            "spearman :  0.6341639740279196\n",
            "mae      :  0.08485453903761837\n",
            "mse      :  0.011637487364086556\n",
            "r2       :  0.2809741656460959\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.6678429730298119\n",
            "spearman :  0.6568058055125834\n",
            "mae      :  0.07496900141336407\n",
            "mse      :  0.009234749134759981\n",
            "r2       :  0.42942810643464235\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.5327112377402287\n",
            "spearman :  0.4959083037345019\n",
            "mae      :  0.10635874201963097\n",
            "mse      :  0.01960525183945077\n",
            "r2       :  -0.21131668035851603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Wyt2GXWXyfWc",
        "outputId": "e07d8bdc-ec32-4d9d-8afe-6893c1a52dfb"
      },
      "source": [
        "'''\n",
        "For file gradient_boosting_baseline.csv\n",
        "pearson  :  0.6911351486877488\n",
        "spearman :  0.6707113273501418\n",
        "mae      :  0.07188171267210111\n",
        "mse      :  0.008743365608190055\n",
        "r2       :  0.459788392905934\n",
        "'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFor file gradient_boosting_baseline.csv\\npearson  :  0.6911351486877488\\nspearman :  0.6707113273501418\\nmae      :  0.07188171267210111\\nmse      :  0.008743365608190055\\nr2       :  0.459788392905934\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSCRrmPT7DsI"
      },
      "source": [
        "## Testing Multi Word Complexity Prediction - Multi Token Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMfhnAW7PFu"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines/multi\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA09b98F7QpW"
      },
      "source": [
        "sentences_train_list = list(data_multi['sentence'])\n",
        "complexity_train_list = list(data_multi['complexity'])\n",
        "tokens_train_list = list(data_multi['token'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bXYLdho7XIS",
        "outputId": "0543830f-d4af-4403-ab0a-1d3cea684609"
      },
      "source": [
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1517, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Al--XE7ZpC"
      },
      "source": [
        "test_df = pd.read_csv(os.path.join(DATA_FOLDER, \"lcp_multi_test_preprocessed.csv\"), index_col=0)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9AgvW6X7fD0",
        "outputId": "0c76e042-6b7f-43ea-eff5-2a63317ca1a3"
      },
      "source": [
        "test_df['token'] = test_df['token'].astype(str)\n",
        "test_df['sentence'] = test_df['sentence'].astype(str)\n",
        "sentences_test_list = list(test_df['sentence'])\n",
        "test_tokens_list = list(test_df['token'])\n",
        "testdf_vectors = get_embeddings(sentences_test_list, test_tokens_list)\n",
        "testdf_vectors.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(184, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkCh1HO77hks"
      },
      "source": [
        "# Linear Regression\n",
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJZrqiNW7mAA",
        "outputId": "38463b21-e70a-4868-b4a9-774a27433740"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_multi_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.7384735689252496\n",
            "spearman :  0.7096751511559939\n",
            "mae      :  0.08420414291697727\n",
            "mse      :  0.011177467719053704\n",
            "r2       :  0.5369181534723191\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.7823878559554673\n",
            "spearman :  0.7546944249875555\n",
            "mae      :  0.07924415256123464\n",
            "mse      :  0.00953696812319659\n",
            "r2       :  0.6048839576394317\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.7988214260459509\n",
            "spearman :  0.7780559066252843\n",
            "mae      :  0.07713078050256739\n",
            "mse      :  0.009342698342090006\n",
            "r2       :  0.6129325435285244\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.7747686594582374\n",
            "spearman :  0.7563503882622532\n",
            "mae      :  0.07906457106883466\n",
            "mse      :  0.009776174954316456\n",
            "r2       :  0.5949736323456092\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.5617861056424609\n",
            "spearman :  0.5658144254122174\n",
            "mae      :  0.1236007498123032\n",
            "mse      :  0.024975175150413018\n",
            "r2       :  -0.03472007405490074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "NQN4WIQOy8Fw",
        "outputId": "c1951b73-3c64-45aa-8cca-b7d28eeba54f"
      },
      "source": [
        "'''\n",
        "For file ada_boost_baseline.csv\n",
        "pearson  :  0.7988214260459509\n",
        "spearman :  0.7780559066252843\n",
        "mae      :  0.07713078050256739\n",
        "mse      :  0.009342698342090006\n",
        "r2       :  0.6129325435285244\n",
        "'''"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFor file ada_boost_baseline.csv\\npearson  :  0.7988214260459509\\nspearman :  0.7780559066252843\\nmae      :  0.07713078050256739\\nmse      :  0.009342698342090006\\nr2       :  0.6129325435285244\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY8C4i6388GE"
      },
      "source": [
        "## Testing Multi Word Predictions - with Single + Multi Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoPL9dGw7o7i"
      },
      "source": [
        "SUBMISSION_FOLDER = os.path.join(FOLDER_PATH,\"predictions/baselines/multi\")\n",
        "\n",
        "if( not os.path.exists(SUBMISSION_FOLDER)):\n",
        "    os.makedirs(SUBMISSION_FOLDER)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW1Bsn6l84VS",
        "outputId": "22c4bf65-87d7-4193-d41c-14b28c988a29"
      },
      "source": [
        "sentences_train_list = list(data['sentence'])\n",
        "complexity_train_list = list(data['complexity'])\n",
        "tokens_train_list = list(data['token'])\n",
        "\n",
        "vectors = get_embeddings(sentences_train_list, tokens_train_list)\n",
        "print(vectors.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9179, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wOtIFEb9Vqu"
      },
      "source": [
        "reg = LinearRegression().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/linear_regression_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# Gradient Boosting\n",
        "reg = GradientBoostingRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/gradient_boosting_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# AdaBoost\n",
        "reg = AdaBoostRegressor().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/ada_boost_baseline.csv\", index=False, header=False)\n",
        "\n",
        "\n",
        "# SVM regressor\n",
        "reg = SVR().fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/SVM_baseline.csv\", index=False, header=False)\n",
        "\n",
        "# MLP Regressor\n",
        "reg = MLPRegressor(hidden_layer_sizes=(150)).fit(vectors, np.array(complexity_train_list))\n",
        "y_pred = reg.predict(testdf_vectors)\n",
        "\n",
        "pred = pd.DataFrame({\"ID\":test_df.index, \"complexity\":y_pred})\n",
        "pred.to_csv(SUBMISSION_FOLDER+\"/MLP_baseline.csv\", index=False, header=False)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5-LaFi-9adZ",
        "outputId": "63d95f23-4bf7-46ef-8a19-a201d017c022"
      },
      "source": [
        "evaluate(SUBMISSION_FOLDER, FOLDER_PATH+\"/references/lcp_multi_test_labelled_preprocessed.csv\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For file linear_regression_baseline.csv\n",
            "pearson  :  0.8179201155507047\n",
            "spearman :  0.8049744407871943\n",
            "mae      :  0.10626544460880245\n",
            "mse      :  0.0162353528148035\n",
            "r2       :  0.3273702640454511\n",
            "\n",
            "For file gradient_boosting_baseline.csv\n",
            "pearson  :  0.8193283866008076\n",
            "spearman :  0.8090107910611813\n",
            "mae      :  0.10516079075843644\n",
            "mse      :  0.01603721066214149\n",
            "r2       :  0.3355792820659891\n",
            "\n",
            "For file ada_boost_baseline.csv\n",
            "pearson  :  0.7715057753961843\n",
            "spearman :  0.7468502086000744\n",
            "mae      :  0.1002614955390914\n",
            "mse      :  0.015038504834717827\n",
            "r2       :  0.3769556072163568\n",
            "\n",
            "For file SVM_baseline.csv\n",
            "pearson  :  0.8137261535536578\n",
            "spearman :  0.8074492340697415\n",
            "mae      :  0.07244008552665147\n",
            "mse      :  0.008700322647294615\n",
            "r2       :  0.6395461317210687\n",
            "\n",
            "For file MLP_baseline.csv\n",
            "pearson  :  0.6534750568487009\n",
            "spearman :  0.632187822519071\n",
            "mae      :  0.10611963154645704\n",
            "mse      :  0.01823920316785689\n",
            "r2       :  0.24435085884732366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FGvYcQATzxQN",
        "outputId": "8c87e50e-5cd4-4283-e647-0f50f24709bc"
      },
      "source": [
        "'''\n",
        "For file gradient_boosting_baseline.csv\n",
        "pearson  :  0.8193283866008076\n",
        "spearman :  0.8090107910611813\n",
        "mae      :  0.10516079075843644\n",
        "mse      :  0.01603721066214149\n",
        "r2       :  0.3355792820659891\n",
        "'''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nFor file gradient_boosting_baseline.csv\\npearson  :  0.8193283866008076\\nspearman :  0.8090107910611813\\nmae      :  0.10516079075843644\\nmse      :  0.01603721066214149\\nr2       :  0.3355792820659891\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr8C8GQrz2Dw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}