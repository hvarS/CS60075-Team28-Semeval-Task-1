{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3EKBTxPQ1wmc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "import syllables \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from eval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17rFnJ6K1xK8",
    "outputId": "3b3d0205-da7e-46df-f44f-e8954997aaca"
   },
   "outputs": [],
   "source": [
    "word_vector = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xI3DLaXmVS3J",
    "outputId": "487008ce-ab1c-49b3-e301-de8480da2c03"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/MyDrive/nlp_project\n",
    "\n",
    "# !pip install syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9jJLUYF10kL",
    "outputId": "99fa6dae-cd39-4634-e9e0-343a1a18b63f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ankit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1HWw1xv1HsKS"
   },
   "outputs": [],
   "source": [
    "def add_single_features(name,isTrain) :\n",
    "    df = pd.read_csv(\"data/preprocessed/\" +name )\n",
    "\n",
    "    frequency_of_word = {}\n",
    "    for i in range(len(df)) :\n",
    "        word = df.at[i,\"token\"]\n",
    "        if word in frequency_of_word :\n",
    "            frequency_of_word[word]+=1\n",
    "        else :\n",
    "            frequency_of_word[word] = 1\n",
    "\n",
    "    def vowel_count(str): \n",
    "        count = 0\n",
    "        vowel = set(\"aeiouAEIOU\") \n",
    "        for alphabet in str: \n",
    "            if alphabet in vowel: \n",
    "                  count = count + 1\n",
    "        return count \n",
    "\n",
    "\n",
    "    def contain_numeral(str) :\n",
    "        num = \"0123456789\"\n",
    "        for alphabet in str: \n",
    "            if alphabet in num: \n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    token_length=[]\n",
    "    token_syllable= []\n",
    "    token_vowels = []\n",
    "    token_frequency = []\n",
    "    token_contain_numeral = []\n",
    "    nearest_class = []\n",
    "    \n",
    "    for i in range(len(df)) :\n",
    "        word = df.at[i,\"token\"]\n",
    "        if type(word) is not str :\n",
    "            token_length.append(0)\n",
    "            token_syllable.append(0)\n",
    "            token_frequency.append(0)\n",
    "            token_vowels.append(0)\n",
    "            token_contain_numeral.append(False)\n",
    "            if isTrain :\n",
    "                nearest_class.append(round(4*df.at[i,\"complexity\"])+1)   \n",
    "\n",
    "            continue\n",
    "        token_length.append(len(word))\n",
    "        token_syllable.append(syllables.estimate(word))\n",
    "        token_vowels.append(vowel_count(word))\n",
    "        token_frequency.append(frequency_of_word[word])\n",
    "        token_contain_numeral.append(contain_numeral(word))\n",
    "\n",
    "        # print(type(df.at[i,\"complexity\"]))\n",
    "        if isTrain :\n",
    "            nearest_class.append(round(4*df.at[i,\"complexity\"])+1)\n",
    "\n",
    "    df['token_length'] = token_length\n",
    "    df['token_syllable'] = token_syllable\n",
    "    df['token_vowels'] = token_vowels\n",
    "    df['token_frequency'] = token_frequency\n",
    "    df['token_contain_numeral'] = token_contain_numeral\n",
    "    if isTrain :\n",
    "        df['nearest_class'] = nearest_class\n",
    "    df.to_csv(\"data/added_features/\"+name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zQh43VwhJjx0"
   },
   "outputs": [],
   "source": [
    "add_single_features(\"lcp_single_test_preprocessed.csv\",False)\n",
    "add_single_features(\"lcp_single_train_preprocessed.csv\",True)\n",
    "add_single_features(\"lcp_multi_test_preprocessed.csv\",False)\n",
    "add_single_features(\"lcp_multi_train_preprocessed.csv\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygNjyq2Um8PO"
   },
   "source": [
    "###  models on single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "tglUvpkDPzzS",
    "outputId": "b62a9e25-7c54-4b98-e3f9-75470f9faaf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>token_length</th>\n",
       "      <th>token_syllable</th>\n",
       "      <th>token_vowels</th>\n",
       "      <th>token_frequency</th>\n",
       "      <th>token_contain_numeral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39TX062QX1OHFOH8FUL76K5L7D3X3S</th>\n",
       "      <td>bible</td>\n",
       "      <td>speak much prince world come nothing</td>\n",
       "      <td>prince</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3CIS7GGG65JS8I3AZ9RG54AE4MUUEA</th>\n",
       "      <td>bible</td>\n",
       "      <td>house shall turned others field wife together ...</td>\n",
       "      <td>inhabitant</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379OL9DBSSESUVWY1Z8JGBFG9BTY92</th>\n",
       "      <td>bible</td>\n",
       "      <td>stranger terrible nation cut left mountain val...</td>\n",
       "      <td>bough</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3DFYDSXB2W00JYP2DA272KN69UQUJV</th>\n",
       "      <td>bible</td>\n",
       "      <td>sharpen tongue like sword aim arrow deadly word</td>\n",
       "      <td>arrow</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31YWE12TE0CZG7IVH6OXJ1H1CFPX7X</th>\n",
       "      <td>bible</td>\n",
       "      <td>obey leader submit watch behalf soul give acco...</td>\n",
       "      <td>account</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               corpus  \\\n",
       "id                                      \n",
       "39TX062QX1OHFOH8FUL76K5L7D3X3S  bible   \n",
       "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA  bible   \n",
       "379OL9DBSSESUVWY1Z8JGBFG9BTY92  bible   \n",
       "3DFYDSXB2W00JYP2DA272KN69UQUJV  bible   \n",
       "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X  bible   \n",
       "\n",
       "                                                                         sentence  \\\n",
       "id                                                                                  \n",
       "39TX062QX1OHFOH8FUL76K5L7D3X3S               speak much prince world come nothing   \n",
       "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA  house shall turned others field wife together ...   \n",
       "379OL9DBSSESUVWY1Z8JGBFG9BTY92  stranger terrible nation cut left mountain val...   \n",
       "3DFYDSXB2W00JYP2DA272KN69UQUJV    sharpen tongue like sword aim arrow deadly word   \n",
       "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X  obey leader submit watch behalf soul give acco...   \n",
       "\n",
       "                                     token  token_length  token_syllable  \\\n",
       "id                                                                         \n",
       "39TX062QX1OHFOH8FUL76K5L7D3X3S      prince             6               2   \n",
       "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA  inhabitant            10               4   \n",
       "379OL9DBSSESUVWY1Z8JGBFG9BTY92       bough             5               1   \n",
       "3DFYDSXB2W00JYP2DA272KN69UQUJV       arrow             5               2   \n",
       "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X     account             7               2   \n",
       "\n",
       "                                token_vowels  token_frequency  \\\n",
       "id                                                              \n",
       "39TX062QX1OHFOH8FUL76K5L7D3X3S             2                5   \n",
       "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA             4                3   \n",
       "379OL9DBSSESUVWY1Z8JGBFG9BTY92             2                2   \n",
       "3DFYDSXB2W00JYP2DA272KN69UQUJV             2                3   \n",
       "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X             3                4   \n",
       "\n",
       "                                token_contain_numeral  \n",
       "id                                                     \n",
       "39TX062QX1OHFOH8FUL76K5L7D3X3S                  False  \n",
       "3CIS7GGG65JS8I3AZ9RG54AE4MUUEA                  False  \n",
       "379OL9DBSSESUVWY1Z8JGBFG9BTY92                  False  \n",
       "3DFYDSXB2W00JYP2DA272KN69UQUJV                  False  \n",
       "31YWE12TE0CZG7IVH6OXJ1H1CFPX7X                  False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"data/added_features\"\n",
    "df_Train = pd.read_csv(os.path.join(data_folder,\"lcp_single_train_preprocessed.csv\"),index_col=0)\n",
    "df_Test = pd.read_csv(os.path.join(data_folder,\"lcp_single_test_preprocessed.csv\"),index_col=0)\n",
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CR0rYPVNfW0g",
    "outputId": "5889f31f-469c-40bc-b9f3-94aa67a5adb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7662, 305)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_feature = np.array(df_Train[['token_length','token_syllable','token_vowels','token_frequency','token_contain_numeral']])\n",
    "\n",
    "embed_word = np.array(list(df_Train['token'].apply(lambda x:word_vector[x] if x in word_vector else word_vector['unk'])))\n",
    "embed_sentence = np.array(list(df_Train['sentence'].apply\n",
    "    (\n",
    "    lambda x:\n",
    "    sum([word_vector[w] if w in word_vector else word_vector['unk'] for w in x.split()])/len(x.split())\n",
    "    )\n",
    "                              )\n",
    "                         )\n",
    "Train_Vector = np.hstack((stat_feature,.5*embed_word+.5*embed_sentence))\n",
    "Train_Vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvNsj9g5q1KM",
    "outputId": "2ab8eff5-7b56-43c0-96d1-cdb04202c6be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917, 305)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_feature = np.array(df_Test[['token_length','token_syllable','token_vowels','token_frequency','token_contain_numeral']])\n",
    "\n",
    "embed_word = np.array(list(df_Test['token'].apply(lambda x:word_vector[x] if x in word_vector else word_vector['unk'])))\n",
    "embed_sentence = np.array(list(df_Test['sentence'].apply\n",
    "    (\n",
    "    lambda x:\n",
    "    sum([word_vector[w] if w in word_vector else word_vector['unk'] for w in x.split()])/len(x.split())\n",
    "    )\n",
    "                              )\n",
    "                         )\n",
    "Test_Vector = np.hstack((stat_feature,.5*embed_word+.5*embed_sentence))\n",
    "Test_Vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XQEjt5cPvjcc"
   },
   "outputs": [],
   "source": [
    "submission_folder = \"predictions/single_with_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pRFS8Mvlv_Tc"
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "reg = LinearRegression().fit(Train_Vector, np.array(df_Train['complexity']))\n",
    "y_pred = reg.predict(Test_Vector)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":df_Test.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/linear_regression_with_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L30VeUnexNzQ"
   },
   "outputs": [],
   "source": [
    "# SVM regressor\n",
    "reg = SVR().fit(Train_Vector, np.array(df_Train['complexity']))\n",
    "y_pred = reg.predict(Test_Vector)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":df_Test.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/SVM_with_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "81Ionk_jxf8C"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "reg = GradientBoostingRegressor().fit(Train_Vector, np.array(df_Train['complexity']))\n",
    "y_pred = reg.predict(Test_Vector)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":df_Test.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/gradient_boosting_with_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gcqtLvUTxrF6"
   },
   "outputs": [],
   "source": [
    "# MLP Regressor\n",
    "regr = MLPRegressor(hidden_layer_sizes=(150)).fit(Train_Vector, np.array(df_Train['complexity']))\n",
    "y_pred = reg.predict(Test_Vector)\n",
    "\n",
    "pred = pd.DataFrame({\"ID\":df_Test.index, \"complexity\":y_pred})\n",
    "pred.to_csv(submission_folder+\"/MLP_with_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fb3PIE5RyMO1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file MLP_with_features.csv\n",
      "pearson  :  0.6510099362950927\n",
      "spearman :  0.6197440617933732\n",
      "mae      :  0.07254862857837216\n",
      "mse      :  0.009343434124671623\n",
      "r2       :  0.4227129699873945\n",
      "\n",
      "For file linear_regression_with_features.csv\n",
      "pearson  :  0.6311508461209863\n",
      "spearman :  0.6077421054566633\n",
      "mae      :  0.07661968054084875\n",
      "mse      :  0.009917703426107611\n",
      "r2       :  0.3872315597232592\n",
      "\n",
      "For file gradient_boosting_with_features.csv\n",
      "pearson  :  0.6510099362950927\n",
      "spearman :  0.6197440617933732\n",
      "mae      :  0.07254862857837216\n",
      "mse      :  0.009343434124671623\n",
      "r2       :  0.4227129699873945\n",
      "\n",
      "For file SVM_with_features.csv\n",
      "pearson  :  0.6744168783485909\n",
      "spearman :  0.6307686935582127\n",
      "mae      :  0.07273162781364834\n",
      "mse      :  0.008875871431429068\n",
      "r2       :  0.4516014787439301\n"
     ]
    }
   ],
   "source": [
    "evaluate(submission_folder, \"references/lcp_single_test_labelled_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlpTask1",
   "language": "python",
   "name": "nlptask1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
